<?xml version="1.0"?>
<document>
  <id>2241869</id>
  <title>Model-based variance-stabilizing transformation for Illumina microarray data
</title>
  <abstract>
 Variance stabilization is a step in the preprocessing of microarray data that can greatly benefit the performance of subsequent statistical modeling and inference. Due to the often limited number of technical replicates for Affymetrix and cDNA arrays, achieving variance stabilization can be difficult. Although the Illumina microarray platform provides a larger number of technical replicates on each array (usually over 30 randomly distributed beads per probe), these replicates have not been leveraged in the current log2 data transformation process. We devised a variance-stabilizing transformation (VST) method that takes advantage of the technical replicates available on an Illumina microarray. We have compared VST with log2 and Variance-stabilizing normalization (VSN) by using the Kruglyak bead-level data (2006) and Barnes titration data (2005). The results of the Kruglyak data suggest that VST stabilizes variances of bead-replicates within an array. The results of the Barnes data show that VST can improve the detection of differentially expressed genes and reduce false-positive identifications. We conclude that although both VST and VSN are built upon the same model of measurement noise, VST stabilizes the variance better and more efficiently for the Illumina platform by leveraging the availability of a larger number of within-array replicates. The algorithms and Supplementary Data are included in the lumi package of Bioconductor, available at: www.bioconductor.org.
</abstract>
  <content>
 Illumina is a recent microarray platform for gene expression profiling (1). One of the unique and potentially advantageous features of the Illumina array is that each probe [called a &#x2018;reporter&#x2019; in the MIAME ontology (2)] is measured 30 (25% quantile, on a representative Human-6 chip) to 45 (75% quantile) times (variations exist from probe to probe and from chip to chip) on independent beads that are spatially distributed at random locations on each array. In contrast, spotted microarrays usually measure each probe one to three times, with spots (called &#x2018;features&#x2019; in the MIAME ontology) arranged at fixed locations. Due to the larger number of technical replicates of beads within each Illumina array and their spatial randomness, we can obtain a more robust estimate of the hybridization intensity (point estimate by mean) and the measurement error (spread estimate by variance) for each probe (a 50-mer). In the following discussion, we will focus on probe-level data analysis; for probe-to-gene mapping of Illumina arrays, please refer to Du et al. (3). With the unique design of Illumina, we can model the functional relationship between the mean and the variance for each array directly, which was impossible with the previous microarray platforms. This capability is critical to the application of the method described in this paper for calculating the optimal transformation. So far, the preprocessing of Illumina data largely follows the tradition of base-2 logarithmic (log2) transformation learned from the Affymetrix platform (4), which does not take advantage of all of the information present in an Illumina microarray experiment, in particular the larger number of technical replicates. Variance stabilization is one of the primary reasons that microarray raw data are always log-transformed before further analysis (5). Generally, larger intensities tend to have larger variations when repeatedly measured. This violation of a constant variance across the measurement range, which is described as &#x2018;heteroskedasticity&#x2019; in statistics, imposes a serious challenge when applying canonical linear models or analysis of variance (ANOVA) to microarray data (6). So that these well-established and well-understood statistical models can be applied to microarray data, a data transformation strategy is usually applied to abrogate or at least reduce the heteroskedasticity. Various methods have been examined, such as taking the logarithm, generalized logarithm (6,7) and Box&#x2013;Cox power transformation (5). The simplest and most widely used one is the log2-based transformation. However, there are three major problems associated with logarithmic transformation. First, it is a one-size-fits-all solution, ignoring the measurement noise characteristics associated with each instrument and each run. Second, negative values that frequently result from background correction of low-intensity signals have to be reset before taking the logarithm, and thus they are artificially truncated. Third, logarithmic transformation inflates variances when the intensities are close to zero although it stabilizes the variances at higher intensities: Durbin et al. (6) have shown that the variance approaches infinity as the mean approaches zero when a log transformation is applied. Consequently, this can confound the interpretation of log-transformed microarray results. For example, a 2-fold difference can be very significant when the intensities are high; however, when the intensities are close to the background level a 2-fold difference can be within the expected measurement error. To solve these problems, Huber and colleagues (7) used a measurement-noise model, which was first proposed by Rocke and Durbin (8), to optimally estimate the parameters in a generalized logarithmic transformation; the implementation was called variance-stabilizing normalization (VSN). The VSN method calculates the optimal transformation parameter by indirectly modeling repeated measurements across microarrays and assumes that most non-differentially expressed genes are technical replicates. We believe that for Illumina microarrays these assumptions are not required to calculate variance. For instance, an asymptotic variance-stabilizing transformation (VST) can be derived more efficiently if the relationship between the mean and the variance can be characterized directly (9). The variance stabilization method presented in this paper takes advantage of the bead-level, within-array, technical replicates generated from Illumina microarrays to model the mean&#x2013;variance relationship. This allows us to calculate parameters necessary for the optimal data transformation directly from each array. As such, we do not need multiple arrays to calculate the data transformation parameters. This approach isolates the concerns of the optimal normalization method from the issues of data transformation. As this transformation uses the same variance stabilization approach as VSN but without a linear normalization method, we simply refer it as VST, for &#x2018;variance-stabilizing transformation&#x2019;. We have validated this approach by calculating the variance-versus-mean dependency within an array before and after applying the VST algorithm. We present evidence that the application of the VST transformation followed by normalization can successfully stabilize the variance of between-chip replicates. We have also evaluated this approach using a benchmark data set of titrations (4) to examine the impact of data transformation on the detection of differentially expressed genes. The results show that VST can improve both the detection of differentially expressed genes and reduce false-positive identifications. Due to the nature of the multiplicative and additive processes involved in the labeling reaction, in the photon detection system and in signal amplification, microarray raw intensity measurements always demonstrate an intensity-dependent (non-linear) measurement variation (7,8,10). Moreover, the relationship between the measured intensity and its variance differs from equipment to equipment and from array to array. To model the bead-to-bead measurement variation of each probe in each microarray, we assume a general measurement model with both additive and multiplicative errors, which is widely used in analytical chemistry (7,8,10):1where Y is the measured intensity value; &#x3B1; is the offset; &#x3BC; is the noise-free value in arbitrary units; and &#x3B5; and &#x3B7; are additive and multiplicative error terms, respectively, which are assumed to be independent and Gaussian-distributed with zero mean. Thus, the mean and variance of measurement Y can be estimated by:23where m&#x3B7; and  are the mean and the variance of e&#x3B7;, respectively, and &#x3C3;&#x3B5; is the standard deviation of &#x3B5;. Substituting &#x3BC; in Equation (3) with its estimate in Equation (2), we can derive the relationship between the mean, u, and the variance, v, of measurement Y, which can be expressed in a quadratic form:4 Equation (4) indicates an undesirable dependency of intensity variance, v, on the mean, u. In order to facilitate subsequent data analysis, which usually assumes that v and u are independent, a VST is necessary. We expect to find a transformation function h for Y,5such that the variance Var() of transformed  does not depend on the mean E(). By using the delta method, the asymptotic VST function h can be derived as (9):6 Therefore, as long as we can estimate the intensity variance, v, and mean, u, of each probe (presumably hybridizing to a single gene), we can infer the functions v(u) and h(y), and stabilize the variance by following Equations (4) and (6). For other microarray platforms, like Affymetrix and cDNA arrays, the accurate estimation of v and u is difficult. This is because large numbers of technical replicates of the probe usually do not exist within each array and the number of replicates using separate arrays is usually limited due to experimental and cost considerations. Further, cross-array (inter-array) normalization must be done (as integrated in the VSN implementation), and all of these factors confound the estimation of v and u. In contrast, for a probe on an Illumina microarray, there are typically over 30 measurements using identical beads. This simplifies and improves the accuracy of the estimation of v and u. (A) The relations between standard deviation and mean of bead-level replicates of each probe in one representative microarray (titration ratio of 100:0 of the Barnes data set). The green line represents a linear fitting. (B) Log2 versus VST transformed values. The green line in Figure A is the fitted curve; the green dotted line in Figure B represents Log2 = VST. The plots are based on the first sample (titration ratio of 100:0) of the Barnes data set. (A) The relations between standard deviation and mean of bead-level replicates of each probe in one representative microarray (titration ratio of 100:0 of the Barnes data set). The green line represents a linear fitting. (B) Log2 versus VST transformed values. The green line in Figure A is the fitted curve; the green dotted line in Figure B represents Log2 = VST. The plots are based on the first sample (titration ratio of 100:0) of the Barnes data set. This procedure improves the reliability and robustness of the estimation of c1 and c2, since the dynamic range of the standard deviation is much smaller than the variance and the linear fitting is used (See Figure 1 and Supplementary Figure 2). Substituting c1, c2 and c3 into Equation (6) yields:8 There are several equivalent ways to write Equation (8) (7,11). Our expression is similar to that of Huber et al. (7). Equation (8) indicates that the log transform is a special case for h(y) when c3 = 0 or when the intensity measurement is large and c3 &gt; 0; note that in our case c3 is larger than zero. Select the background probes, which have non-significant detection P-values (higher than a predefined P-value threshold, 0.01 by default); estimate the variance of the background noise, c3, by taking the mean of the expression variance of the background probes; estimate c1 and c2 by linear fitting, as shown in Equation (7); and compute the transformed value  based on Equation (8). compute the transformed value  based on Equation (8). As log2-transformed data are widely used, we added a linear transformation  to approximate a log2 transformation for probes with high signal intensities (Linear transformation will not affect the variance stabilization). This enables the direct incorporation of the VST results into existing procedures for normalization and analysis. Figure 1B shows an example of the relationship between a VST transform and a log2 transform. It indicates that the VST-transform is very close to log2 when the probe intensity measurement value is high (larger than 29 in this case), but compressed for low-intensity values. Currently, there are few publicly available benchmark data sets to evaluate the Illumina platform; as far as we know, none of them is provided with bead-level output under differentially expressed conditions. Thus, we used two data sets to evaluate the VST algorithm. The Kruglyak data measured the Total Human Reference RNA (Stratagene, Inc.) on one microarray using Illumina Sentrix Human-6 Expression BeadChip version 1.0 (12). They were the only public data we could find that output the hybridization intensities of individual beads. Raw hybridization intensities provided by Illumina were used without any further preprocessing. We used this data set to evaluate the effectiveness of different variance stabilization methods on bead replicates. The Barnes data set (4) measured a titration series (alternatively, it can be viewed as a dilution series) of two human tissues: blood and placenta. There are six samples with the titration ratios of blood and placenta at 100:0, 95:5, 75:25, 50:50, 25:75 and 0:100. The samples were hybridized on the pre-released HumanRef-8 BeadChip version 1.0 (Illumina, Inc.) in duplicate. We noticed that the number of bead-per-probe type of the Barnes data set ranges from 19 (25% quantile) to 30 (75% quantile), which is lower than the commercially released versions. We used this data set to evaluate the detection of differentially expressed genes. To give the hybridization intensities a meaningful origin for the titration analysis, the Barnes data have been background-adjusted by subtracting the median of negative control probes (using non-detected probes as a proxy). As the Illumina BeadStudio output file has included the estimation of the mean (the AVG_Signal column, which is the mean after removing outliers as estimated by 3 MADs) and the standard error of the mean (the BEAD_STDERR column, which is the standard error of the mean after removing the outliers) of each probe, we did not recalculate the mean and standard deviation directly from the bead-level data. First, we translated the standard error of the mean into the standard deviation: , where STDERR is the standard error of the mean, and N is the number of the beads for the probe; then we fitted the probe mean and variance relations, as shown in Equation (4). For normalization, we used quantile normalization (13); thus, the BeadStudio normalization option was turned off. A study of the combinatorial interplay between the background correction, data transformation, normalization and differential detection methods, similar to the work of Choe et al. (14), is beyond the scope of this paper. We used the functions in the &#x2018;lumi&#x2019; Bioconductor package to do all the processing (available at www.bioconductor.org). A vignette that includes all the scripts to process the Barnes data set is in the Supplementary Data. Users can easily reproduce the results shown in the following section, and check the results under different parameter settings. To evaluate the variance-stabilizing capability of different data transformations, we first evaluated their effects on bead-level replicates within a single microarray by the following steps: (i) Specify the transforming function, h(y); for VST, it is estimated using the probe intensity mean and variance; (ii) transform the intensity value of each bead-replicate, yi, into ; and (iii) Estimate the variance and mean of the transformed value . After an optimal VST, we would expect the intensity mean and variance of the transformed values for the different probes on a chip to be independent of each other, i.e. the variance does not change with the intensity of the measurement. Rank of mean and standard deviation relations of the bead-level data. Each data point represents a probe (usually over 30 beads are used to calculate the statistics of each probe). The red dots depict the running median estimator (window-width 10%). (A) Raw data without transform; (B) VST- transformed; (C) log2-transformed; (D) Cubic root-transformed. For an optimal VST, we would expect there to be no trend between the rank of the mean and the standard deviation. Rank of mean and standard deviation relations of the bead-level data. Each data point represents a probe (usually over 30 beads are used to calculate the statistics of each probe). The red dots depict the running median estimator (window-width 10%). (A) Raw data without transform; (B) VST- transformed; (C) log2-transformed; (D) Cubic root-transformed. For an optimal VST, we would expect there to be no trend between the rank of the mean and the standard deviation. Rank of mean and standard deviation relations of the technical replicate microarrays after preprocessing. The red dots depict the running median estimator (window-width 10%). Plotted are two 100:0 (blood:placenta) replicates in the Barnes data set, which are separately located at two HumanRef-8 BeadChips. (A) VST- transformed and quantile-normalized; (B) log2-transformed and quantile-normalized; (C) Regular VSN-processed. (D) VSN-techReplicate method performed VSN only using the pair of technical replicates. Note: for Figure A&#x2013;C, all six pairs of samples were preprocessed together, although only the replicates of the 100:0 group were plotted. Comparison of the correlation between technical replicates of six different pairs of chips after preprocessing. The VSN-techReplicate indicates that the VSN method was separately applied to each pair of technical replicates. All other methods were applied to the whole data set of six pairs. Comparison of the correlation between technical replicates of six different pairs of chips after preprocessing. The VSN-techReplicate indicates that the VSN method was separately applied to each pair of technical replicates. All other methods were applied to the whole data set of six pairs. Furthermore, VST improves the consistency of technical replicates. Figure 4 shows the boxplot of correlation coefficients from six different pairs of technical replicates after preprocessing. We can see that the VST-quantile method results in the best correlation between technical replicates after preprocessing. Again, VSN-techReplicate procedure outperforms the regular VSN because of the VSN assumption discussed above. In contrast, VST uses technical replicates within each array to estimate optimal transformation parameters, and thus it is not complicated by the relationship across arrays. In the previous section, we evaluated the effects of variance-stabilizing techniques on improving the reproducibility of between-array technical replicates. However, this is only one of the performance criteria that we need to assess: if one only considers making the results of each experiment similar, then an algorithm making all results the same would be the best, which is not our intent. Therefore, we also compared the variation between groups versus the variation within groups: The cumulative distribution of P-values obtained from F-tests. These are measures of the ratio of the between-group variation and within-group variation, or, in other words, the signal-to-noise ratio. Here, a &#x2018;group&#x2019; means the samples with the same titration ratio. The cumulative distribution of P-values obtained from F-tests. These are measures of the ratio of the between-group variation and within-group variation, or, in other words, the signal-to-noise ratio. Here, a &#x2018;group&#x2019; means the samples with the same titration ratio. To better evaluate the &#x2018;real life&#x2019; performance of the VST algorithm, we need to examine how it may facilitate the identification of differentially expressed genes. Currently, there is no spike-in data set (15) available for the Illumina platform. We have selected the Barnes data set, which is a series titration of two tissues at five different titrations, for this purpose. For the Barnes data set, because we do not know which of the signals are coming from &#x2018;true&#x2019; differentially expressed genes, we cannot use an ROC curve (15) to compare the performance of different algorithms. Instead, we assume that if a probe demonstrates the concordant titration behavior across all six conditions, then it is more likely to be a true answer. Following Barnes et al. (4), we defined a concordant probe as a signal from a probe with a correlation coefficient larger than 0.8 between the normalized intensity profile and the real titration profile (six titration ratios with two replicates at each titration). The percentage of concordant probes among the top probes by ranking the F-test P-values. The concordant probes are defined as those with correlation coefficients between the gene expression profile (measured by probe intensities) and the titration profile larger than 0.8. Note that the F-test P-value of the 3000th probe is 0.00019, 0.00022 and 0.00023 (VST-quantile, log2-quantile and VSN, respectively). The percentage of concordant probes among the top probes by ranking the t-test p-values estimated by &#x2018;limma&#x2019; (16). The concordant probes are defined as those with correlation coefficients between the gene expression profile (measured by probe intensities) and the titration profile larger than 0.8. Note that the P-value of the 1000th probe is 0.0013, 0.0079 and 0.0040 (VST-quantile, log2-quantile, and VSN respectively). The percentage of concordant probes among the top probes by ranking the t-test p-values estimated by &#x2018;limma&#x2019; (16). The concordant probes are defined as those with correlation coefficients between the gene expression profile (measured by probe intensities) and the titration profile larger than 0.8. Note that the P-value of the 1000th probe is 0.0013, 0.0079 and 0.0040 (VST-quantile, log2-quantile, and VSN respectively). The most commonly encountered task of microarray data analysis is to compare a treatment condition to a control condition, which is usually done by using a statistical model to adjust the t-test score (16). To mimic real-life applications, we selected for comparison the samples with the smallest titration difference in the Barnes data set (the most challenging comparison), i.e. the samples with the titration ratios of 100:0 and 95:5 (each condition has two technical replicates). Users can easily select other pairs and rerun the vignette (see Supplementary Data) to investigate the corresponding results. We used the Bioconductor &#x2018;limma&#x2019; package (16) to estimate the P-values of the two-condition comparison. Figure 7 shows the percentage of concordant probes among the top probes by ranking the probes&#x2019; P-values from lowest to highest. Again, the VST-Quantile method clearly outperforms the log2-quantile and VSN methods. This suggests that by appropriate data transformation, the statistical test is more likely to pick up the true answers (the ones showing the titration behavior). As such, VST helps to reduce false-positive identifications. Based on the two data sets and different evaluation criteria, we list evidences that the VST transformation successfully stabilizes the variance both within each microarray and between technical replicates over a wide range of intensities. In essence, VST uses an error model that provides a bias against low-intensity values, as these signals are prone to measurement noise. As a result, the VST transformation improves the detection of differentially expressed genes and reduces the selection of discordance genes (more likely to be false positives) in the Barnes data set. VST can be viewed as a generalized log2 transformation, fine-tuned for the noise characteristics of each array based on the model specified in Equation (1). Comparisons of log2, VSN andVST Comparisons of log2, VSN andVST In practice, people often turn off the background subtraction (or even add a positive offset to the microarray measurement values) before they do a logarithm transformation in order to suppress the high variance at the low expression range. In such an empirical approach, the selection of the offset is arbitrary and might not provide uniform performance across chips and experiments. Thus, the final analysis results are very sensitive to which background correction method is used (17). Instead, VST generates an estimate of the offset c2 [Equation (7)] based on the mean and variance relations v(u). The impact of different background correction methods on VST requires further investigation. The VST method and a standard logarithm transformation are also closely related. After examining Equations (4) and (8), we find that the logarithm transformation is a special case of VST when c3 = 0 or the measurement intensity is high. This explains the result in Figure 1B: for large u (intensity) values, the VST method converges to the results from the log transformation. We have noticed that the bias introduced by VST tends to slightly over-suppress the measurements at the low end for some data sets; i.e. under-reporting the difference when the signal is close to the background. This phenomenon is due either to the current implementation or to the fact that real data is more complex than the assumed model in Equation (1). Further investigation is required. In practice, some caution might be necessary when one wants to focus attention on finding differential expression among these marginally expressed genes, although most researchers tend not to give priority to the genes expressed at a very low level compared with background noise. As one reviewer pointed out, the Barnes data set can also be evaluated by looking at the correlation between the expression profile and the titration profile: a favorable data transformation method with low bias would improve the correlation. We investigated this and found that the VST-quantile-processed data have more probes with high correlation between the expression and titration profile. (See the Supplemental Data, Figure 3). A data transformation procedure cannot be evaluated alone without using a normalization procedure. In the current evaluation, we used VST transformation followed by a quantile normalization procedure. The reason for this combination is to provide a more direct comparison with the popular log2-Quantile procedure. Other normalization methods can also be used together with VST transformation. To deal with the heteroskedasticity problem, an alternative to data transformation is to abandon the canonical linear models that require making distribution assumptions. For example, the cyberT-test method (18) uses a moving window to reduce the dependency of variance on expression level. However, these ad hoc modifications cannot be easily generalized to complex experimental designs such as a mixed linear model, nor can they be used to calculate the statistical power of a given sample size. Supplementary Data are available at NAR Online.
</content>
</document>
